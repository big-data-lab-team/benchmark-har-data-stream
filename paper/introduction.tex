\section{Introduction}
\label{sec:introduction}

Internet of Things applications may adopt a
centralized model, where connected objects transfer data to servers with 
adequate computing capabilities, or a decentralized model, where data is analyzed directly on the connected
objects or on nearby devices. While the decentralized model limits network transmission,
increases battery life~\cite{sensor-network-survey, sensor-energy-model},
and reduces data privacy risks, it also raises important processing challenges
due to the modest computing capacity of connected objects. Indeed, it is not uncommon for wearable devices and other smart objects
to include a processing memory of less than 100~KB, little to no storage
memory, a slow CPU, and no operating system. With multiple sensors
producing data at high frequencies, typically 50~Hz to 800~Hz, processing speed and
memory consumption become critical properties of data analyses. 

Data stream processing algorithms are precisely designed to analyze
virtually infinite sequences of data elements with reduced amounts of
working memory. Several classes of stream processing algorithms were
developed in the past decades, such as filtering, counting, or sampling
algorithms~\cite{kejariwal2015}. \TG{Maybe mention a few key properties of streaming algorithms} Our study focuses on supervised
classification, a key component of contemporary data models.

We evaluate supervised data stream classifiers from
the point of view of connected objects, with a particular focus on human
activity recognition. The main motivating use case is that of wearable
sensors measuring 3D acceleration and orientation at different locations on
the human body, from which activities such as gym exercises have to be
predicted. A previously untrained supervised classifier is deployed directly on the wearables or on
a nearby object, perhaps a watch, and aggregates the data, learns a data model, predicts the current
activity, and episodically receives true labels from the human subject. Our
main question is to determine whether on-chip classification is feasible in
this context. 

We evaluate existing classifiers from the complementary angles of (1)
classification performance, including in the presence of concept drift, and
(2) resource consumption, including memory usage and classification time
per element (latency). We consider six datasets in our benchmark, including
the two most popular open datasets used for human activity recognition, and
four simulated datasets. 


%NOTE: Keep the next three lines :D.
%\cite{sensor-energy-consumption} (conclusion, second paragraph) communication uses more energy.
%\cite{leach} and \cite{sensor-energy-model}(page 3, first column, check equations and values)
%\cite{sensor-network-survey} : "Since the sensor nodes are often inaccessible, the lifetime of a sensor network depends on the lifetime of the power resources of the nodes"

% offline works
Several studies evaluated classifiers for human activity recognition in an
offline (non data stream) setting. In particular, the work
in~\cite{Janidarmian_2017} compared 293 classifiers using various sensor
placements and window sizes, concluding on the superiority of k nearest
neighbors (kNN) and pointing out a trade-off between runtime and
classification performance. Resource consumption, including memory and runtime, was also studied 
for offline classifiers, such as in~\cite{memory_consumption_machine_learning}
for the particular case of the R programming language.

% data stream classifiers
Data stream classifiers were also compared, in particular
in~\TG{Martin, add references and a brief summary of results.}
However, these studies remained limited to ... 

Regarding connected objects, the work in~\cite{omid_2019} presents a
wearable system capable of running pre-trained classifiers \TG{Martin,
are they really pre-trained?} with high classification accuracy. It shows
the superiority of the proposed Feedforward Neural Network~(FNN) over KNN
~\TG{Check the spelling of kNN vs KNN and harmonize accordingly}. \TG{any other relevant study on connected objects?}
%  It shows that a trained neural
% network achieves high accuracy and performs better
% than KNN. The dataset was acquired with the
% Neblina, a wearable sensor placed on the right
% forearm. The data from the Neblina was merged to
% send to the computer a stream of 9-axis. Only
% then, the stream was processed to extract features
% and feed the classifier.

Compared to these previous works, the contributions of our paper are the following:
\begin{itemize}
    \item We compare the most popular data stream classifiers on the specific case of human activity recognition;
    \item We provide quantitative measurements of memory and power consumption, as well as runtime;
    \item We implement data stream classifiers in a consistent software library meant for deployment on embedded systems.
\end{itemize} 
The subsequent sections present the materials, methods, and results of our benchmark.

%Étendre related work, regarder les papiers qui ont cité ces papier
%En particulier la référence Janidarmian_2017, pareil pour memory_consumption_machine_learning

% vim: tw=50 ts=2
