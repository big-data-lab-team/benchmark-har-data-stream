\section{Introduction}
\label{sec:introduction}

Internet of Things applications may adopt a centralized model, where connected
objects transfer data to servers with adequate computing capabilities, or a
decentralized model, where data is analyzed directly on the connected objects or
on nearby devices. While the decentralized model limits network transmission,
increases battery life~\cite{sensor-network-survey, sensor-energy-model}, and
reduces data privacy risks, it also raises important processing challenges due
to the modest computing capacity of connected objects. Indeed, it is not
uncommon for wearable devices and other smart objects to include a processing
memory of less than 100~KB, little to no storage memory, a slow CPU, and no
operating system. With multiple sensors producing data at a high frequency,
typically 50~Hz to 800~Hz, processing speed and memory consumption become
critical properties of data analyses. 

Data stream processing algorithms are precisely designed to analyze virtually
infinite sequences of data elements with reduced amounts of working memory.
Several classes of stream processing algorithms were developed in the past
decades, such as filtering, counting, or sampling
algorithms~\cite{kejariwal2015}.  These algorithms must follow multiple
constraints such as a constant processing time per data element, or a constant space
complexity~\cite{issues_learning_from_stream}.  Our study focuses on supervised
classification, a key component of contemporary data models.

We evaluate supervised data stream classifiers from the point of view of
connected objects, with a particular focus on Human Activity Recognition~(\har). The main motivating use case
is that of wearable sensors measuring 3D acceleration and orientation at
different locations on the human body, from which activities such as gym
exercises have to be predicted. A previously untrained supervised classifier is
deployed directly on the wearables or on a nearby object, perhaps a watch, and
aggregates the data, learns a data model, predicts the current activity, and
episodically receives true labels from the human subject. Our main question is
to determine whether on-chip classification is feasible in this context. 

We evaluate existing classifiers from the complementary angles of (1)
classification performance, including in the presence of concept drift, and
(2) resource consumption, including memory usage and classification time
per element (latency). We consider six datasets in our benchmark, including
three that are derived from the two most popular open datasets used for \har, and
three simulated datasets.

Compared to the previous works reviewed in Section~\ref{sec:related-work}, the contributions of our paper are the following:
\begin{itemize}
    \item We compare the most popular data stream classifiers on the specific case of \har;
    \item We provide quantitative measurements of memory and power consumption, as well as runtime;
    \item We implement data stream classifiers in a consistent software library meant for deployment on embedded systems.
\end{itemize} 
The subsequent sections present the materials, methods, and results of our benchmark.

%NOTE: Keep the next three lines :D.
%\cite{sensor-energy-consumption} (conclusion, second paragraph) communication uses more energy.
%\cite{leach} and \cite{sensor-energy-model}(page 3, first column, check equations and values)
%\cite{sensor-network-survey} : "Since the sensor nodes are often inaccessible, the lifetime of a sensor network depends on the lifetime of the power resources of the nodes"

\section{Related Work}

\label{sec:related-work}

To the best of our knowledge, no previous study focused on the comparison
of data stream classifiers for \har in the context of limited memory and
available runtime that characterizes connected objects.

\subsection{Comparisons of data stream classifiers}

% data stream classifiers
Data stream classifiers were compared mostly using synthetic datasets or real
but general-purpose ones (Electrical, CoverType, Poker), which is not
representative of our use case. \revision{There was also comparisons made with
daily human activities such as cooking or cleaning~\cite{HAR_daily_1,
HAR_daily_3, HAR_daily_2}. These studies describe how they have collected
datasets from heterogeneous sensor networks located in appartments. Except for
the Opportunity datasets shown in~\cite{HAR_daily_2}, the data were collected
from sensor placed in various daily objects such as the entrance door or the
cupboard. The Opportunity dataset have, in addition, wearable sensors placed on
the subjects. These papers also provide a baseline F1-score with popular
classifiers (\naivebayes, \knn, and neural network).
} In addition, memory and runtime usage are rarely
reported, with the notable exception of~\cite{StreamDM-CPP}.

The work in~\cite{prasad2016stream} reviews an extensive list of classifiers for
data streams, comparing the \hoeffdingtree, the \naivebayes, and the k-nearest
neighbor~(\knn) online classifiers. The paper reports an accuracy of 92 for
online \knn, 80 for the \hoeffdingtree, and 60 for \naivebayes. The study is
limited to a single dataset (CoverType). 

The work in ~\cite{kaur2020} compares four classifiers (Bayesnet,
\hoeffdingtree, \naivebayes, and Decision Stump) using synthetic datasets.  It
reports a similar accuracy of 90 for the Bayesnet, the \hoeffdingtree, and
\naivebayes classifiers, while the Decision Stump one only reaches 65. Regarding
runtimes, Bayesnet is found to be four times slower than the \hoeffdingtree
which is itself three times slower than \naivebayes and Decision Stump.

The work in~\cite{priya2020comprehensive} compares ensemble classifiers on
imbalanced data streams with concept drifts, using two real datasets
(Electrical, Intrusion), synthetic datasets, and six classifiers, including the
\naivebayes and the \hoeffdingtree ones. The \hoeffdingtree is found to be the
second most accurate classifier after the Accuracy Updated Ensemble.

The authors in~\cite{lopes2020evaluating} have analyzed the resource trade-offs
of six online decision trees applied to edge computing. Their results showed
that the Very Fast Decision Tree and the Strict Very Fast Decision Tree were the
most energy-friendly, the latter having the smallest memory footprint. On the
other hand, the best predictive performances were obtained in combination with
OLBoost. In particular, the paper reports an accuracy of 89.6\% on the
Electrical dataset, and 83.2\% on an Hyperplane dataset.

Finally, the work in~\cite{StreamDM-CPP} describes the architecture of
\streamdmcpp and presents an extensive benchmark of tree-based classifiers,
covering runtime, memory, and accuracy. Compared to other tree-based
classifiers, the \hoeffdingtree classifier is found to have the smallest memory
footprint while the Hoeffding Adaptive Tree classifier is found to be the most
accurate on most of the datasets. 

\subsection{Offline and data stream classifiers for \har}
% offline works
Several studies evaluated classifiers for \har in an offline (non data stream)
setting. In particular, the work in~\cite{Janidarmian_2017} compared 293
classifiers using various sensor placements and window sizes, concluding on the
superiority of k nearest neighbors (\knn) and pointing out a trade-off between
runtime and classification performance. Resource consumption, including memory
and runtime, was also studied for offline classifiers, such as
in~\cite{memory_consumption_machine_learning} for the particular case of the R
programming language.

In addition, the work in \cite{ugulino2012} achieved an offline accuracy of
99.4\% on a five-class dataset of \har. The authors used AdaBoost, an ensemble
method, with ten offline decision trees. The work in \cite{ahmed2019smartphone}
proposes a Support Vector Machine enhanced with feature selection. Using
smartphone data, the model showed above 90\% accuracy on day-to-day human
activities. Finally, the work in \cite{san2018robust} applies three offline
classifiers to smartphone and smartwatch human activity data. Results show that
Convolutional Neural Network and Random Forest achieve F1 score of 0.98 with
smartwatches and 0.99 with smartphones.

%online/stream
In a data stream (online) setting, the work in~\cite{omid_2019} presents a
wearable system capable of running pre-trained classifiers on the chip with high
classification accuracy. It shows the superiority of the proposed \FNN over
\knn.

\revision{
\subsection{Limitation of this study}
This study shows some limitations compare to the state of the art. It studies
\har related to sports activities such as push-up, pull-up, or squat, which
exclude daily activities and the field of Ambient Assisted Living. Additionally,
the study focuses on wearable sensors worn on the forearm. Also, the sensor
count is not important compares to papers with more than 50
sensors~\cite{HAR_daily_1, HAR_daily_3, HAR_daily_2}. Finally, the experiment is
run on a regular computer, so even though we can compare algorithm together, we
may miss behavior related to the device's environment, especially, regarding the
power usage.
}
% vim: tw=80 ts=2
