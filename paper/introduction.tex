\section{Introduction}
\label{sec:introduction}

Internet of Things applications may adopt a centralized model, where connected
objects transfer data to servers with adequate computing capabilities, or a
decentralized model, where data is analyzed directly on the connected objects or
on nearby devices. While the decentralized model limits network transmission,
increases battery life~\cite{sensor-network-survey, sensor-energy-model}, and
reduces data privacy risks, it also raises important processing challenges due
to the modest computing capacity of connected objects. Indeed, it is not
uncommon for wearable devices and other smart objects to include a processing
memory of less than 100~KB, little to no storage memory, a slow CPU, and no
operating system. With multiple sensors producing data at a high frequency,
typically 50~Hz to 800~Hz, processing speed and memory consumption become
critical properties of data analyses. 

Data stream processing algorithms are precisely designed to analyze virtually
infinite sequences of data elements with reduced amounts of working memory.
Several classes of stream processing algorithms were developed in the past
decades, such as filtering, counting, or sampling
algorithms~\cite{kejariwal2015}.  These algorithms must follow multiple
constraints such as a constant processing time per data element, or a constant space
complexity~\cite{issues_learning_from_stream}.  Our study focuses on supervised
classification, a key component of contemporary data models.

We evaluate supervised data stream classifiers from the point of view of
connected objects, with a particular focus on Human Activity Recognition~(\har). The main motivating use case
is that of wearable sensors measuring 3D acceleration and orientation at
different locations on the human body, from which activities such as gym
exercises have to be predicted. A previously untrained supervised classifier is
deployed directly on the wearables or on a nearby object, perhaps a watch, and
aggregates the data, learns a data model, predicts the current activity, and
episodically receives true labels from the human subject. Our main question is
to determine whether on-chip classification is feasible in this context. 

We evaluate existing classifiers from the complementary angles of (1)
classification performance, including in the presence of concept drift, and
(2) resource consumption, including memory usage and classification time
per element (latency). We consider six datasets in our benchmark, including
three that are derived from the two most popular open datasets used for \har, and
three simulated datasets.

Compared to the previous works reviewed in Section~\ref{sec:related-work}, the contributions of our paper are the following:
\begin{itemize}
    \item We compare the most popular data stream classifiers on the specific case of \har;
    \item We provide quantitative measurements of memory and power consumption, as well as runtime;
    \item We implement data stream classifiers in a consistent software library meant for deployment on embedded systems.
\end{itemize} 
The subsequent sections present the materials, methods, and results of our benchmark.

%NOTE: Keep the next three lines :D.
%\cite{sensor-energy-consumption} (conclusion, second paragraph) communication uses more energy.
%\cite{leach} and \cite{sensor-energy-model}(page 3, first column, check equations and values)
%\cite{sensor-network-survey} : "Since the sensor nodes are often inaccessible, the lifetime of a sensor network depends on the lifetime of the power resources of the nodes"

\section{Related Work}

\label{sec:related-work}

To the best of our knowledge, no previous study focused on the comparison
of data stream classifiers for \har in the context of limited memory and
available runtime that characterizes connected objects.

\subsection{Comparisons of data stream classifiers}

% data stream classifiers
Data stream classifiers were compared mostly using synthetic datasets
or real but general-purpose ones (Electrical, CoverType, Poker), which is 
not representative of our use case. In addition, memory and runtime usage 
are rarely reported, with the notable exception of~\cite{StreamDM-CPP}.

The work
in~\cite{prasad2016stream} reviews an extensive list of classifiers for
data streams, comparing the \hoeffdingtree, the \naivebayes, and the \knn
online classifiers. The paper reports an accuracy of 92 for online \knn, 80
for the \hoeffdingtree, and 60 for \naivebayes. The study is limited to a
single dataset (CoverType). 

The work in ~\cite{kaur2020} compares four classifiers (Bayesnet,
\hoeffdingtree, \naivebayes, and Decision Stump) using synthetic datasets.
It reports a similar accuracy of 90 for the Bayesnet, the
\hoeffdingtree, and \naivebayes classifiers, while the Decision Stump one
only reaches 65. Regarding runtimes, Bayesnet is found to be four times
slower than the \hoeffdingtree which is itself three times slower than
\naivebayes and Decision Stump.

The work in~\cite{priya2020comprehensive} compares ensemble classifiers on
imbalanced data streams with concept drifts, using two real datasets
(Electrical, Intrusion), synthetic datasets, and six classifiers, including the
\naivebayes and the \hoeffdingtree ones. The \hoeffdingtree is found to be
the second most accurate classifier after the Accuracy Updated Ensemble.

The authors in~\cite{lopes2020evaluating} have analyzed the resource trade-offs
of six online decision trees applied to edge computing. Their results showed that the
Very Fast Decision Tree and the Strict Very Fast Decision Tree were the most
energy-friendly, the latter having the smallest memory footprint. On the
other hand, the best predictive performances were obtained in combination with
OLBoost. In particular, the paper reports an accuracy of 89.6\% on the Electrical
dataset, and 83.2\% on an Hyperplane dataset.

Finally, the work in~\cite{StreamDM-CPP} describes the architecture of
\streamdmcpp and presents an extensive benchmark of tree-based classifiers,
covering runtime, memory, and accuracy. Compared to other tree-based
classifiers, the \hoeffdingtree classifier is found to have the smallest
memory footprint while the Hoeffding Adaptive Tree classifier is found to be
the most accurate on most of the datasets. 

\subsection{Offline and data stream classifiers for \har}

% offline works
Several studies evaluated classifiers for \har in an offline (non data stream)
setting. In particular, the work in~\cite{Janidarmian_2017} compared 293
classifiers using various sensor placements and window sizes, concluding on the
superiority of k nearest neighbors (\knn) and pointing out a trade-off between
runtime and classification performance. Resource consumption, including memory
and runtime, was also studied for offline classifiers, such as
in~\cite{memory_consumption_machine_learning} for the particular case of the R
programming language.

In addition, the work in \cite{ugulino2012} achieved an offline accuracy of
99.4\% on a five-class dataset of \har. The authors used AdaBoost, an
ensemble method, with ten offline decision trees. The work in
\cite{ahmed2019smartphone} proposes a Support Vector Machine enhanced with
feature selection. Using smartphone data, the model showed above 90\%
accuracy on day-to-day human activities. Finally, the work in
\cite{san2018robust} applies three offline classifiers to smartphone and
smartwatch human activity data. Results show that Convolutional Neural Network and Random
Forest achieve F1 score of 0.98 with smartwatches and 0.99 with
smartphones.

%online/stream
In a data stream (online) setting, the work in~\cite{omid_2019} presents a wearable
system capable of running pre-trained classifiers on the chip with high classification
accuracy. It shows the superiority of the proposed Feedforward Neural
Network~(FNN) over \knn.






%  It shows that a trained neural
% network achieves high accuracy and performs better
% than KNN. The dataset was acquired with the
% Neblina, a wearable sensor placed on the right
% forearm. The data from the Neblina was merged to
% send to the computer a stream of 9-axis. Only
% then, the stream was processed to extract features
% and feed the classifier.



%Étendre related work, regarder les papiers qui ont cité ces papier
%En particulier la référence Janidarmian_2017, pareil pour memory_consumption_machine_learning

% vim: tw=80 ts=2
