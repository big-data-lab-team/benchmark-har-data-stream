\section{Discussion}
%Mondrian has the greatest F1-scores, however, slow runtime
From this study, we observed that the \hoeffdingtree algorithm presents the
best classification performances followed by the \naivebayes and the
\mondrianforest.  However, these performances come with a cost.  The
\naivebayes does not adapt to the drift, the \mondrianforest is the slowest
classifier with a high variance. And the \hoeffdingtree has a growing memory
footprint.

%All F1-scores remains low
We also observed that most of the f1-scores are low with the RandomTree dataset and
the real datasets (\banosdataset, \recofitdataset). On the other hand, the most
performant classifier (\mondrianforest, \hoeffdingtree, and \naivebayes) have high
F1-scores with the datasets Hyperplane and RandomRBF. The main difference we
observed between these datasets is the lower complexity of the last two.
Indeed, the Hyperplane and RandomRBF datasets have two classes with three
attributes while the others have at least ten classes. The two real datasets
have 33 and 41 classes. Therefore, we should focus to adapt these classifiers
to work with a high number of classes.

The next step to adapt these classifiers, \mondrianforest in particular, to real-life
situations would be to reduce their runtime, make them less dependent on the
memory available, and to make them more efficient with a high number of
classes. Additionally, running a classifier on a sensor to minimize data
communication favorise the use of one sensor.

%Link with litterature

%Pk 1 capteur
In this study, we focused on using one sensor rather than all the sensors
available in the real datasets because it is more likely for a user to have one
sensor. It is cheaper to buy or build one sensor, and it is faster to setup.

%Pk 3 axes.

%Puissance, pk pas de différence significative (platform)
Section~\ref{sec:result-power} shows no power difference between classifiers. This
observation is explainable by two factors. The platform used is too powerful
and it was already working at minimal power. Indeed, to ensure no disturbance
by a background process, we run the classifier on an isolated cluster node with
eight cores. Therefore, the power difference on one core is not noticeable.

Another reason is the dataset size. Indeed, the slowest run is about
10 seconds with 50 Mondrian trees on \recofitdataset dataset.  Such short
execution does not leave the time for the CPU to switch P-states because it
barely warms a core.

% Mémoire contrainte, partir sur l'exploration : toute xp faite à mémoire constante, qu'est-ce qu'il se passe ac' + de mémoire.
In section~\ref{sec:result-memory}, we differentiated bounded memory and
constant space complexity. In the first case, a limited amount of memory
may impact the classifier performances because the classifier has to find a way
around this lack of memory: stop growing or making space for new data.
On the other hand, a constant space complexity is a feature of a classifier and
its performances are not expected to change no  matter the amount of memory
available. The classifier is simply supposed to fail without the required
amount of memory. From the algorithm involved in this study, \mondrianforest
has a bounded memory policy while \naivebayes is a classifier with a constant
space complexity.

With that being said, this memory-bound explains the poor performance of the
\mondrianforest with 50 trees compare to the one with 5 or 10 trees. Indeed, we
have noticed that 50 trees fill the allocated memory after a few elements,
thus, preventing the classifier to adapt.  

Note that we selected the memory bound does not match all situations. Indeed,
depending on the connected object the memory limit can range from few KB to GB.
In this study, the \mondrianforest and the \FNN are both limited to 600~KB.

%Hoeffding Tree insane performance on RandomTree
Concerning the high performance of the \hoeffdingtree on
Figure~\ref{fig:f1-dataset_3}, we would like to remind that the RandomTree
dataset is a synthetic dataset generated using a tree structure. Therefore, we
expected the tree-based classifiers to show better performances.  However, we
noticed that from the two tree-based classifiers, only the \hoeffdingtree
achieved such performance.  We suspect this difference to be caused by the lack
of split optimization in the Mondrian trees. Indeed, the \mondrianforest behavior is
more related to a nearest neighboor because it tries to split the space in
boxes of equal sizes rather than finding the best split. The good prediction is
then obtained by combining multiple trees in a forest.

Figure~\ref{fig:f1-banos} has shown that the \FNN has a low
F1-score compare to other classifiers. It contradicts the results
depicted in~\cite{omid_2019} where \FNN achieves more than 95\% 
accuracy. The main difference between~\cite{omid_2019} and this study comes
from the training set. Not only the training set includes examples from every
subjects, but also the windows are overlapping and wider than the ones we used.
Therefore, we expect the \FNN to have already encountered
most of the datapoints from the testing set. When instead of using only the
first subject of the \banosdataset dataset we used a sample of 10\% of it, we
managed to reach an F1-score slightly above 0.6, which is close to the \naivebayes.

Note that the pre-training of the \FNN is a bit different from the other
classifiers. Indeed, the hyperparameters tuning of the other classifiers
implies that they start the testing phase with no prior knowledge of the
dataset even about the element seen in the tuning phase. On the other hand, the
\FNN starts with its weights already set, therefore we can say that it has
already seen part of the dataset. We proceed that way because it takes many
epochs for the weights to adjust correctly so if the weights were randomly
initialized for the testing phase, the \FNN would answer randomly.

We deviated from the method for the \FNN classifier because neural networks have
shown a wide range of classification abilities depending on how they are used.
Therefore, we tried to follow~\cite{omid_2019} which exhibits high classification
performance.

We have shown in Figure~\ref{fig:f1-drift} that only two classifiers
(\hoeffdingtree, \mcnn) adapt to concept drift. However, we also observed
that this drift impacts neither the power consumption nor the runtime.
The memory footprint of the \hoeffdingtree is left unchanged by the drift.
We suspect that with an amount of memory large enough, the \mondrianforest would
be able to adapt to the drift. Nevertheless, the drift occurs way after the
available memory is full.
