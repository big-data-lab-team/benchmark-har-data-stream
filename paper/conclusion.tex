\section{Conclusion}
In this study, we observed that the \hoeffdingtree, the \mondrianforest, and
the \naivebayes showed an overall superiority for Human Activity Recognition on
data streams. Noticeably, we observed that the \hoeffdingtree is consistently
in the three best classifiers. We have also noticed that the \mondrianforest is
among the top three classi with four datasets and that it could be the first
with even more memory.  On the other hand, the predictions performances remain
quite low compared to their offline counterpart and the F1-score vary with the
dataset. Additionally, we have observed that the \mcnn classifier would achieve
better performances than the \naivebayes on two of the synthetic datasets. 
We also discovered that the \hoeffdingtree and the \mcnns were more resilient
to a drift that the others.  We learn that a memory-bound has an important
impact on the classification performances of the \mondrianforest, to the point
where it cannot learn nor adapt to a drift.  Finally, we found out that the
classifier used does not have an impact on power consumption.

As future works, we suggest focusing the research to decrease the memory need
of the \hoeffdingtree and the \mondrianforest. We also advise to improve the
runtime to make these classifiers competitive with \mcnn and \FNN. Most of all
we suggest improving the classification performance of the learning
algorithms.
