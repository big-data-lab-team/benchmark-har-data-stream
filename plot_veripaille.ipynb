{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "This file contains all the code useful to data analysis.\n",
    "Some cells may take a 15 minutes to process. Likely long processes will be indicated with #long.\n",
    "Read comment for parts adapted to your outputs.\n",
    "\n",
    "Below is the cell deemed necessary for most sections. Each section is to be run sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import os\n",
    "import csv\n",
    "import statistics, re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# useful functions for all data extraction\n",
    "def line_style(name, exponent):\n",
    "    if int(name[9:-19])==1:\n",
    "        style='-'\n",
    "    elif int(name[9:-19])==5:\n",
    "        style='--'\n",
    "    elif int(name[9:-19])==10:\n",
    "        style='-.'\n",
    "    elif int(name[9:-19])==50:\n",
    "        style=':'\n",
    "    if exponent>=10: #coloring of the curves\n",
    "        color='violet'\n",
    "    elif exponent>=9:\n",
    "        color='royalblue'\n",
    "    elif exponent>=8:\n",
    "        color='cyan'\n",
    "    elif exponent>=7:\n",
    "        color='turquoise'\n",
    "    elif exponent>=6:\n",
    "        color='green'\n",
    "    elif exponent>=5:\n",
    "        color='yellowgreen'\n",
    "    elif exponent>=4:\n",
    "        color='gold'\n",
    "    elif exponent>=3:\n",
    "        color='orange'\n",
    "    elif exponent>=2:\n",
    "        color='chocolate'\n",
    "    else:\n",
    "        color='red'\n",
    "    return style, color\n",
    "#processing output from file to pandas dataframe\n",
    "def process_output(output_filename, run_output_filename, model_filename):\n",
    "    def add_names(row, models):\n",
    "        key = str(int(row['model_id']))\n",
    "        name = models[key]['name']\n",
    "        if name == 'Mondrian':\n",
    "            return name + ' ' + models[key]['tree_count'] + ' tree(s) (RAM x' + str(int(models[key]['memory_size']) / 600000) + ')'\n",
    "        elif name == 'MCNN':\n",
    "            if models[key]['cleaning'] == '1':\n",
    "                return 'MCNN Origin ' + models[key]['cluster_count'] + ' clusters'\n",
    "            elif models[key]['cleaning'] == '2':\n",
    "                return 'MCNN Mixe ' + models[key]['cluster_count'] + ' clusters'\n",
    "            else:\n",
    "                return 'MCNN OrpailleCC ' + models[key]['cluster_count'] + ' clusters'\n",
    "        elif name == 'StreamDM HoeffdingTree':\n",
    "            return name\n",
    "        else:\n",
    "            return models[key]['fullname']\n",
    "    def add_files(row, models):\n",
    "        return models[str(int(row['model_id']))]['file']\n",
    "    def add_color(row, models):\n",
    "        return models[str(int(row['model_id']))]['color']\n",
    "    def add_library(row, models):\n",
    "        if models[str(int(row['model_id']))]['fullname'].find('StreamDM') >= 0:\n",
    "            return 'StreamDM'\n",
    "        return 'OrpailleCC'\n",
    "    def add_algorithm(row, models):\n",
    "        if models[str(int(row['model_id']))]['fullname'].find('Naive') >= 0:\n",
    "            return 'NaiveBaye'\n",
    "        if models[str(int(row['model_id']))]['fullname'].find('Naive') >= 0:\n",
    "            return 'NaiveBaye'\n",
    "        if models[str(int(row['model_id']))]['fullname'].find('Mondrian') >= 0:\n",
    "            return 'Mondrian Forest'\n",
    "        if models[str(int(row['model_id']))]['fullname'].find('MCNN') >= 0:\n",
    "            return 'MCNN'\n",
    "        if models[str(int(row['model_id']))]['fullname'].find('MLP') >= 0:\n",
    "            return 'MLP'\n",
    "        if models[str(int(row['model_id']))]['fullname'].find('FNN') >= 0:\n",
    "            return 'FNN'\n",
    "        return 'Unknown'\n",
    "\n",
    "    models = read_models(model_filename)\n",
    "    output = pd.read_csv(output_filename)\n",
    "    output_runs = pd.read_csv(run_output_filename)\n",
    "    output.columns = ['model_id', 'run_id', 'element_count', 'seed', 'accuracy', 'f1', 'memory']\n",
    "    output_runs.columns = ['model_id', 'run_id', 'time', 'energy', 'power']\n",
    "    output['fullname'] = output.apply(lambda r: add_names(r, models), axis=1)\n",
    "    output['file'] = output.apply(lambda r: add_files(r, models), axis=1)\n",
    "    #print(\"Adding to output run\")\n",
    "    output_runs['fullname'] = output_runs.apply(lambda r: add_names(r, models), axis=1)\n",
    "    output_runs['file'] = output_runs.apply(lambda r: add_files(r, models), axis=1)\n",
    "    output_runs['color'] = output_runs.apply(lambda r: add_color(r, models), axis=1)\n",
    "    output_runs['library'] = output_runs.apply(lambda r: add_library(r, models), axis=1)\n",
    "    output_runs['algorithm'] = output_runs.apply(lambda r: add_algorithm(r, models), axis=1)\n",
    "    return (output, output_runs, models)\n",
    "#recognize the model, more could be added besides Mondrian trees.\n",
    "def read_models(filename):\n",
    "    models = {}\n",
    "    model_file = open(filename, \"r\")\n",
    "    csv_structure = csv.reader(model_file)\n",
    "    for row in csv_structure:\n",
    "        color = hashStringToColor(row[1] + \"\".join(row[3:]))\n",
    "        models[row[0]] = {\"name\": row[1], \"file\": row[2], \"color\": color}\n",
    "        if row[1] == 'Mondrian':\n",
    "            models[row[0]][\"lifetime\"] = row[3]\n",
    "            models[row[0]][\"base\"] = row[4]\n",
    "            models[row[0]][\"discount\"] = row[5]\n",
    "            models[row[0]][\"tree_count\"] = row[6]\n",
    "            models[row[0]][\"memory_size\"] = row[7]\n",
    "            models[row[0]][\"fullname\"] = \"Mondrian T\" + row[1][row[1].find(\"Mondrian\")+8:] + \" \" + row[3] + \"-\" + row[4] + \"-\" + row[5]\n",
    "        elif row[1] == \"FNN\":\n",
    "            models[row[0]][\"fullname\"] = \"FNN\"\n",
    "        else:\n",
    "            models[row[0]][\"fullname\"] = models[row[0]][\"name\"]\n",
    "    return models\n",
    "def stdev(l):\n",
    "    if len(l) <= 1:\n",
    "        return 0.0\n",
    "    return statistics.stdev(l)\n",
    "def hashStringToColor(string):\n",
    "    hsh = hash(string)\n",
    "    r = (hsh & 0xFF0000) >> 16\n",
    "    g = (hsh & 0x00FF00) >> 8\n",
    "    b = hsh & 0x0000FF\n",
    "    return \"#\" + format(r, \"02x\") + format(g, \"02x\") + format(b, \"02x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction for paper\n",
    "The paper is available at https://www.overleaf.com/read/rtvpkqksbqxj. All data extracted is obtained using the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Figure 1.  Difference between the F1 score obtained at precision i and the F1 score of the same model at double precision (52 bits) with  3.0  MB  of  memory.\n",
    "Run all cells. Adapt the first lines to the number of trees you want to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the trees to plot.\n",
    "tr = {1:'-',5:'--',10:'-.',50:':'}\n",
    "number_of_trees = tr[5] # Number of trees here.\n",
    "\n",
    "# Function\n",
    "def print_dif(output, output_runs, models, axs):\n",
    "    def add_key(key):\n",
    "        name = models[0][key]['name']\n",
    "        if name == 'Mondrian':\n",
    "            ram_count = str(int(models[0][key]['memory_size']) / 600000)\n",
    "            return (name + ' ' + models[0][key]['tree_count'] + ' tree(s) (RAM x' + ram_count + ')', key, (name + ' (RAM x' + ram_count + ')', int(models[0][key]['tree_count'])))\n",
    "        else:\n",
    "            return (name, key, (name, 0))\n",
    "    knn_offline_f1 = {'banos_6': 0.86, 'recofit_6': 0.40}\n",
    "    #(print name, key in models, tuple for sorting)\n",
    "    keys = [add_key(key) for key in models[0] if models[0][key]['fullname'] != 'Previous']\n",
    "    #grounp the third and second value to use dict to do a unique\n",
    "    keys = dict([(key[0], (key[1], key[2])) for key in keys]).items()\n",
    "    #Unpack the value part to separate the key and the sorting tuple\n",
    "    keys = [(key[0], key[1][0], key[1][1]) for key in keys]\n",
    "    keys = sorted(keys, key = lambda x: x[2])\n",
    "    names = [key[0] for key in keys]\n",
    "    plt.rcParams.update({'font.size': 33})\n",
    "    list_datasets = ['banos_6','recofit_6'] # modifity for your dataset names, if testing with other datasets.\n",
    "    for dat, dataset_name in enumerate(list_datasets):\n",
    "        print('Dataset: ' + dataset_name)\n",
    "        daty, daty_std = [], []\n",
    "        for i, precision in enumerate(PRECISIONS):\n",
    "            datytmp = output[i][output[i].file.str.contains(dataset_name)]\n",
    "            daty_stdtmp = datytmp[['fullname', 'element_count', 'f1', 'accuracy', 'memory']].groupby(['fullname', 'element_count']).std().reset_index()\n",
    "            datytmp = datytmp[['fullname', 'element_count', 'f1', 'accuracy', 'memory']].groupby(['fullname', 'element_count']).mean().reset_index()\n",
    "            daty.append(datytmp)\n",
    "            daty_std.append(daty_stdtmp)\n",
    "        #F1 Score DIF\n",
    "        axs[dat].plot([-100000,100000],[0.05,0.05], color='darkgrey',linewidth=2.0,linestyle='--')\n",
    "        axs[dat].plot([-100000,100000],[-0.05,-0.05], color='darkgrey',linewidth=2.0,linestyle='--')\n",
    "        for name in names:\n",
    "            if name[-4:]=='5.0)':\n",
    "                for i, precision in enumerate(PRECISIONS):\n",
    "                    style, color = line_style(name, precision)\n",
    "                    if style==number_of_trees: # number of trees to plot\n",
    "                        if i<11:\n",
    "                            y1 = daty[i][daty[i].fullname == name]['f1']-daty[-1][daty[-1].fullname == name]['f1'] - daty_std[i][daty_std[i].fullname == name]['f1']\n",
    "                            y2 = daty[i][daty[i].fullname == name]['f1']-daty[-1][daty[-1].fullname == name]['f1'] + daty_std[i][daty_std[i].fullname == name]['f1']\n",
    "                            axs[dat].fill_between(daty_std[i][daty_std[i].fullname == name]['element_count'], y1, y2, color=color, linestyle=style, alpha=0.05)\n",
    "                        axs[dat].plot(daty[i][daty[i].fullname == name]['element_count'],daty[i][daty[i].fullname == name]['f1']-daty[-1][daty[-1].fullname == name]['f1'], markevery=0.1, markersize=15, color=color,linewidth=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#long\n",
    "#Data extraction, putting results in lists.\n",
    "dir_name = 'node_results'\n",
    "exp = '11'\n",
    "output_lst, output_run_lst, models_lst = [], [], []\n",
    "PRECISIONS = range(1,52)\n",
    "for i in PRECISIONS:\n",
    "    output, output_runs, models = process_output(\"{}/{}_output_{}\".format(dir_name,exp,i),\"{}/{}_output_runs_{}\".format(dir_name,exp,i),\"{}/{}_models_{}.csv\".format(dir_name,exp,i))\n",
    "    output_lst.append(output)\n",
    "    output_run_lst.append(output_runs)\n",
    "    models_lst.append(models)\n",
    "dir_name = 'whole_results'\n",
    "output_lst2, output_run_lst2, models_lst2= [], [], []\n",
    "PRECISIONS = range(1,52)\n",
    "for i in PRECISIONS:\n",
    "    output, output_runs, models = process_output(\"{}/{}_output_{}\".format(dir_name,exp,i),\"{}/{}_output_runs_{}\".format(dir_name,exp,i),\"{}/{}_models_{}.csv\".format(dir_name,exp,i))\n",
    "    output_lst2.append(output)\n",
    "    output_run_lst2.append(output_runs)\n",
    "    models_lst2.append(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: banos_6\n",
      "Dataset: recofit_6\n",
      "Dataset: banos_6\n",
      "Dataset: recofit_6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "fig = plt.figure(figsize=(30, 20))\n",
    "gs = fig.add_gridspec(2, 2, hspace=0.05, wspace=0.05)\n",
    "(ax1, ax2), (ax3, ax4) = gs.subplots(sharex='col', sharey='row')\n",
    "PRECISIONS = range(1,52)\n",
    "print_dif(output_lst, output_run_lst, models_lst, [ax1,ax2])\n",
    "PRECISIONS = range(1,52)\n",
    "print_dif(output_lst2, output_run_lst2, models_lst2, [ax3,ax4])\n",
    "ticks = np.linspace(0,1,5)\n",
    "for ax in [ax1,ax2,ax3,ax4]: #uniform axes\n",
    "    ax.set(xlabel='% of dataset', ylabel='Change in Performance (\\u0394 F1)')\n",
    "    ax.set_ylim([-0.15, 0.08])\n",
    "    if ax==ax1 or ax==ax3:\n",
    "        ax.set_xticks(14200*ticks) # values\n",
    "        ax.set_xlim([-14400*0.03, 14400+14400*0.03])\n",
    "    else:\n",
    "        ax.set_xticks(84800*ticks)\n",
    "        ax.set_xlim([-84800*0.03, 84800+84800*0.03])\n",
    "    ax.label_outer()\n",
    "plt.savefig(\"difplot.png\") #Name of the plot.\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Figure 2. F1 Score of the uninstrumented classifiers with 0.6 MB and 1.2 MB, NI and WI classifiers at 4 bit exponent and 3 bitprecision (8 bits) with 1.2 MB.\n",
    "Run all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-8d9d980f7eff>:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  file1 = np.genfromtxt('{}_results/{}_output_{}'.format(m[0], m[-1], m[-2]), delimiter=',', dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "#long\n",
    "#Array generation\n",
    "model=[['node',0,52,11],['node',1,52,11],['node',1,3,4],['whole',1,3,4]]\n",
    "f1 = np.zeros((len(model), 98)) # Number of classifiers in models.csv\n",
    "for i, m in enumerate(model):\n",
    "    file1 = np.genfromtxt('{}_results/{}_output_{}'.format(m[0], m[-1], m[-2]), delimiter=',', dtype=np.float)\n",
    "    for atts in file1:\n",
    "        if (atts[2]==84800 and atts[0]>=84) or (atts[2]==14200 and atts[0]<84): #difference in datasets\n",
    "            f1[i,int(atts[0])]+= atts[-2]\n",
    "f1/=30 #averaging\n",
    "arr = np.zeros((4,8))\n",
    "for i,m in enumerate(model):\n",
    "    for j, k in enumerate(range(4*m[1],4*(m[1]+1))):\n",
    "        arr[i][j]=f1[i][:12][k]\n",
    "        arr[i][j+4]=f1[i][84:96][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "fig = plt.figure(figsize=(30, 12))\n",
    "gs = fig.add_gridspec(1,2, hspace=0.05, wspace=0.05)\n",
    "(ax1, ax2) = gs.subplots(sharey='row')\n",
    "for i, dataset,ax in zip(range(2),['banos', 'recofit'],(ax1,ax2)):\n",
    "    x = range(1,5)\n",
    "    ax.plot(x, arr[0][4*i:4*i+4], c=\"red\", linestyle='--', marker='o', markersize=4, label=\"Uninstrumented, 0.6 MB\")\n",
    "    ax.plot(x, arr[1][4*i:4*i+4], c=\"red\", marker='o', markersize=4, label=\"Uninstrumented, 1.2 MB\")\n",
    "    ax.plot(x, arr[2][4*i:4*i+4], c=\"blue\", marker='o', markersize=4, label=\"Node, 1.2 MB\")\n",
    "    ax.plot(x, arr[3][4*i:4*i+4], c=\"green\", marker='o', markersize=4, label=\"Whole, 1.2 MB\")\n",
    "    ax.set_xticks(x) # values\n",
    "    ax.set_xticklabels([1,5,10,50]) # labels\n",
    "    \n",
    "for ax in [ax1,ax2]:\n",
    "    ax.set(xlabel='Number of trees', ylabel='F1')\n",
    "    ax.set_ylim([0, 0.65])\n",
    "    ax.grid()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.label_outer()\n",
    "plt.savefig(\"gain.png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TABLE 2: F1 score differences with reduced exponent lengths\n",
    "Run all cells. This is meant for Latex input, observe arr if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&\\cTab{-43.21}&\\cTab{-4.46}&\\cTab{-0.00}&\\cTab{-0.00}\n",
      "&\\cTab{-53.74}&\\cTab{-1.57}&\\cTab{0.00}&\\cTab{0.00}\n",
      "&\\cTab{-53.44}&\\cTab{-1.73}&\\cTab{0.00}&\\cTab{0.00}\n",
      "&\\cTab{-39.71}&\\cTab{-0.47}&\\cTab{0.00}&\\cTab{0.00}\n",
      "&\\cTab{-46.28}&\\cTab{-8.78}&\\cTab{0.00}&\\cTab{0.00}\n",
      "&\\cTab{-63.34}&\\cTab{-4.04}&\\cTab{0.00}&\\cTab{0.00}\n",
      "&\\cTab{-63.96}&\\cTab{-3.31}&\\cTab{0.00}&\\cTab{-0.00}\n",
      "&\\cTab{-54.82}&\\cTab{-1.55}&\\cTab{-0.00}&\\cTab{0.00}\n",
      "&\\cTab{-17.63}&\\cTab{-12.91}&\\cTab{-0.31}&\\cTab{0.00}\n",
      "&\\cTab{-14.91}&\\cTab{-10.70}&\\cTab{-0.09}&\\cTab{-0.00}\n",
      "&\\cTab{-9.96}&\\cTab{-7.00}&\\cTab{-0.00}&\\cTab{-0.00}\n",
      "&\\cTab{-4.82}&\\cTab{-2.25}&\\cTab{0.00}&\\cTab{0.00}\n",
      "&\\cTab{-21.27}&\\cTab{-16.01}&\\cTab{-0.42}&\\cTab{-0.00}\n",
      "&\\cTab{-22.14}&\\cTab{-17.26}&\\cTab{-0.18}&\\cTab{0.00}\n",
      "&\\cTab{-19.66}&\\cTab{-15.21}&\\cTab{-0.08}&\\cTab{0.00}\n",
      "&\\cTab{-10.03}&\\cTab{-7.17}&\\cTab{-0.01}&\\cTab{-0.00}\n"
     ]
    }
   ],
   "source": [
    "# Exponent analysis table generation, node.\n",
    "precisions=[52]\n",
    "exponents= [2,3,4,5,11]\n",
    "f1 = np.zeros((len(precisions), len(exponents), 98)) # Number of classifiers in models.csv\n",
    "for instr in ['node']:#['node', 'whole']:\n",
    "    for pi, p in enumerate(precisions):\n",
    "        for ei, e in enumerate(exponents):\n",
    "            file1 = np.genfromtxt('{}_results/{}_output_{}'.format(instr, e, p), delimiter=',', dtype=float)\n",
    "            for atts in file1:\n",
    "                if (atts[2]==84800 and atts[0]>=84) or (atts[2]==14200 and atts[0]<84): #difference in datasets\n",
    "                    f1[pi,ei,int(atts[0])]+= atts[-2]\n",
    "f1/=30\n",
    "arr = np.zeros((2,3,4,5))\n",
    "for k in range(12):\n",
    "    for e, b in enumerate(f1):\n",
    "        for p, a in enumerate(b):\n",
    "            arr[0][k//4][k%4][p]=(a[:12]-f1[-1][-1][:12])[k]*100\n",
    "            arr[1][k//4][k%4][p]=(a[84:96]-f1[-1][-1][84:96])[k]*100\n",
    "for i in range(2):\n",
    "    for j in [0,2]:\n",
    "        for k in range(4):\n",
    "            print(\"&\\cTab{{{:.2f}}}&\\cTab{{{:.2f}}}&\\cTab{{{:.2f}}}&\\cTab{{{:.2f}}}\".format(arr[i][j][k][0],arr[i][j][k][1],arr[i][j][k][2],arr[i][j][k][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&\\cTab{-0.4628}&\\cTab{-0.0006}&\\cTab{-0.0000}\n",
      "&\\cTab{-0.5590}&\\cTab{-0.0137}&\\cTab{0.0000}\n",
      "&\\cTab{-0.5404}&\\cTab{-0.0309}&\\cTab{-0.0000}\n",
      "&\\cTab{-0.3984}&\\cTab{-0.1729}&\\cTab{0.0000}\n",
      "&\\cTab{-0.4840}&\\cTab{-0.0002}&\\cTab{0.0000}\n",
      "&\\cTab{-0.6130}&\\cTab{-0.0009}&\\cTab{0.0000}\n",
      "&\\cTab{-0.5937}&\\cTab{-0.0078}&\\cTab{-0.0000}\n",
      "&\\cTab{-0.4798}&\\cTab{-0.1351}&\\cTab{-0.0000}\n",
      "&\\cTab{-0.4923}&\\cTab{-0.0001}&\\cTab{-0.0000}\n",
      "&\\cTab{-0.6571}&\\cTab{-0.0031}&\\cTab{0.0000}\n",
      "&\\cTab{-0.6586}&\\cTab{-0.0091}&\\cTab{0.0000}\n",
      "&\\cTab{-0.5590}&\\cTab{-0.1388}&\\cTab{-0.0000}\n",
      "&\\cTab{-0.1856}&\\cTab{-0.0121}&\\cTab{-0.0000}\n",
      "&\\cTab{-0.1552}&\\cTab{-0.0389}&\\cTab{0.0000}\n",
      "&\\cTab{-0.1069}&\\cTab{-0.0260}&\\cTab{-0.0000}\n",
      "&\\cTab{-0.0548}&\\cTab{-0.0260}&\\cTab{0.0000}\n",
      "&\\cTab{-0.2066}&\\cTab{0.0088}&\\cTab{-0.0000}\n",
      "&\\cTab{-0.1874}&\\cTab{-0.0017}&\\cTab{0.0000}\n",
      "&\\cTab{-0.1577}&\\cTab{-0.0235}&\\cTab{-0.0000}\n",
      "&\\cTab{-0.0753}&\\cTab{-0.0220}&\\cTab{0.0000}\n",
      "&\\cTab{-0.2237}&\\cTab{0.0159}&\\cTab{0.0000}\n",
      "&\\cTab{-0.2321}&\\cTab{0.0360}&\\cTab{-0.0000}\n",
      "&\\cTab{-0.2058}&\\cTab{0.0212}&\\cTab{-0.0000}\n",
      "&\\cTab{-0.1073}&\\cTab{-0.0107}&\\cTab{-0.0000}\n"
     ]
    }
   ],
   "source": [
    "# Exponent analysis table generation,whole.\n",
    "precisions=[52]\n",
    "exponents= [3,4,5,11]\n",
    "f1 = np.zeros((len(precisions), len(exponents), 98)) # Number of classifiers in models.csv\n",
    "for instr in ['whole']:#['node', 'whole']:\n",
    "    for pi, p in enumerate(precisions):\n",
    "        for ei, e in enumerate(exponents):\n",
    "            file1 = np.genfromtxt('{}_results/whole_results/{}_output_{}'.format(instr, e, p), delimiter=',', dtype=float)\n",
    "            for atts in file1:\n",
    "                if (atts[2]==84800 and atts[0]>=84) or (atts[2]==14200 and atts[0]<84): #difference in datasets\n",
    "                    f1[pi,ei,int(atts[0])]+= atts[-2]\n",
    "f1/=30\n",
    "arr = np.zeros((2,3,4,4))\n",
    "for k in range(12):\n",
    "    for e, b in enumerate(f1):\n",
    "        for p, a in enumerate(b):\n",
    "            arr[0][k//4][k%4][p]=(a[:12]-f1[-1][-1][:12])[k]\n",
    "            arr[1][k//4][k%4][p]=(a[84:96]-f1[-1][-1][84:96])[k]\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        for k in range(4):\n",
    "            print(\"&\\cTab{{{:.4f}}}&\\cTab{{{:.4f}}}&\\cTab{{{:.4f}}}\".format(arr[i][j][k][0],arr[i][j][k][1],arr[i][j][k][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TABLE 3: F1  score  differences  with  reduced  mantissa  precision\n",
    "Modify the instrumentation as necessary, between 'node' and 'whole'. This is meant for Latex input, observe arr if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&\\dTab{-0.0755}&\\dTab{-0.0570}&\\dTab{-0.0330}&\\dTab{-0.0239}&\\dTab{-0.0072}&\\dTab{-0.0064}\n",
      "&\\dTab{-0.0935}&\\dTab{-0.0603}&\\dTab{-0.0272}&\\dTab{-0.0124}&\\dTab{-0.0055}&\\dTab{-0.0059}\n",
      "&\\dTab{-0.1150}&\\dTab{-0.0510}&\\dTab{-0.0172}&\\dTab{-0.0090}&\\dTab{-0.0038}&\\dTab{-0.0041}\n",
      "&\\dTab{-0.2147}&\\dTab{-0.1505}&\\dTab{-0.0773}&\\dTab{-0.0111}&\\dTab{0.0020}&\\dTab{0.0011}\n",
      "&\\dTab{-0.0705}&\\dTab{-0.0647}&\\dTab{-0.0271}&\\dTab{-0.0193}&\\dTab{-0.0165}&\\dTab{0.0016}\n",
      "&\\dTab{-0.1087}&\\dTab{-0.0678}&\\dTab{-0.0309}&\\dTab{-0.0177}&\\dTab{-0.0098}&\\dTab{-0.0069}\n",
      "&\\dTab{-0.1203}&\\dTab{-0.0624}&\\dTab{-0.0217}&\\dTab{-0.0107}&\\dTab{-0.0011}&\\dTab{-0.0030}\n",
      "&\\dTab{-0.2223}&\\dTab{-0.1351}&\\dTab{-0.0513}&\\dTab{-0.0049}&\\dTab{0.0025}&\\dTab{0.0001}\n",
      "&\\dTab{-0.0737}&\\dTab{-0.0660}&\\dTab{-0.0331}&\\dTab{-0.0348}&\\dTab{-0.0127}&\\dTab{-0.0051}\n",
      "&\\dTab{-0.1038}&\\dTab{-0.0729}&\\dTab{-0.0294}&\\dTab{-0.0149}&\\dTab{-0.0106}&\\dTab{-0.0068}\n",
      "&\\dTab{-0.1228}&\\dTab{-0.0648}&\\dTab{-0.0199}&\\dTab{-0.0122}&\\dTab{-0.0033}&\\dTab{-0.0042}\n",
      "&\\dTab{-0.2035}&\\dTab{-0.0994}&\\dTab{-0.0405}&\\dTab{-0.0079}&\\dTab{0.0023}&\\dTab{0.0002}\n",
      "&\\dTab{-0.0024}&\\dTab{0.0121}&\\dTab{0.0093}&\\dTab{0.0058}&\\dTab{0.0031}&\\dTab{0.0014}\n",
      "&\\dTab{0.0159}&\\dTab{0.0214}&\\dTab{0.0088}&\\dTab{0.0076}&\\dTab{0.0066}&\\dTab{0.0026}\n",
      "&\\dTab{0.0103}&\\dTab{0.0206}&\\dTab{0.0127}&\\dTab{0.0123}&\\dTab{0.0038}&\\dTab{0.0024}\n",
      "&\\dTab{0.0112}&\\dTab{0.0077}&\\dTab{0.0018}&\\dTab{0.0019}&\\dTab{0.0018}&\\dTab{0.0007}\n",
      "&\\dTab{0.0084}&\\dTab{0.0203}&\\dTab{0.0099}&\\dTab{0.0132}&\\dTab{0.0046}&\\dTab{0.0052}\n",
      "&\\dTab{0.0197}&\\dTab{0.0295}&\\dTab{0.0176}&\\dTab{0.0131}&\\dTab{0.0043}&\\dTab{0.0057}\n",
      "&\\dTab{0.0091}&\\dTab{0.0227}&\\dTab{0.0135}&\\dTab{0.0132}&\\dTab{0.0052}&\\dTab{0.0053}\n",
      "&\\dTab{0.0071}&\\dTab{0.0058}&\\dTab{0.0010}&\\dTab{0.0020}&\\dTab{0.0021}&\\dTab{0.0011}\n",
      "&\\dTab{0.0124}&\\dTab{0.0282}&\\dTab{0.0177}&\\dTab{0.0148}&\\dTab{0.0071}&\\dTab{0.0105}\n",
      "&\\dTab{0.0322}&\\dTab{0.0426}&\\dTab{0.0341}&\\dTab{0.0268}&\\dTab{0.0177}&\\dTab{0.0115}\n",
      "&\\dTab{0.0181}&\\dTab{0.0356}&\\dTab{0.0300}&\\dTab{0.0264}&\\dTab{0.0142}&\\dTab{0.0060}\n",
      "&\\dTab{0.0097}&\\dTab{0.0147}&\\dTab{0.0036}&\\dTab{0.0038}&\\dTab{0.0038}&\\dTab{0.0004}\n"
     ]
    }
   ],
   "source": [
    "# Precision analysis table generation.\n",
    "instrumentation='whole'\n",
    "import numpy as np\n",
    "precisions=[1,2,3,4,5,6,52]\n",
    "exponents= [11]\n",
    "f1 = np.zeros((len(precisions), len(exponents), 98)) # Number of classifiers in models.csv\n",
    "for instr in [instrumentation]:#['node', 'whole']:\n",
    "    for pi, p in enumerate(precisions):\n",
    "        for ei, e in enumerate(exponents):\n",
    "            file1 = np.genfromtxt('{}_results/{}_output_{}'.format(instr, e, p), delimiter=',', dtype=float)\n",
    "            for atts in file1:\n",
    "                if (atts[2]==84800 and atts[0]>=84) or (atts[2]==14200 and atts[0]<84): #difference in datasets\n",
    "                    f1[pi,ei,int(atts[0])]+= atts[-2]\n",
    "f1/=30\n",
    "arr = np.zeros((2,3,4,7))\n",
    "for k in range(12):\n",
    "    for p, b in enumerate(f1):\n",
    "        for e, a in enumerate(b):\n",
    "            arr[0][k//4][k%4][p]=(a[:12]-f1[-1][-1][:12])[k]\n",
    "            arr[1][k//4][k%4][p]=(a[84:96]-f1[-1][-1][84:96])[k]\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        for k in range(4):\n",
    "            print(\"&\\dTab{{{:.4f}}}&\\dTab{{{:.4f}}}&\\dTab{{{:.4f}}}&\\dTab{{{:.4f}}}&\\dTab{{{:.4f}}}&\\dTab{{{:.4f}}}\".format(arr[i][j][k][0],arr[i][j][k][1],arr[i][j][k][2],arr[i][j][k][3],arr[i][j][k][4],arr[i][j][k][5],arr[i][j][k][6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction for data analysis.\n",
    "All plots in the results zip that are in the node or whole folders are used for data analysis. All data is plotted for give much more information. These plots are not used in the paper, but can be useful for in-depth analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions. Adapt if needed to the metrics wanted in the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(output, output_runs, models, output_directory=\".\"):\n",
    "    def add_key(key):\n",
    "        name = models[0][key]['name']\n",
    "        if name == 'Mondrian':\n",
    "            ram_count = str(int(models[0][key]['memory_size']) / 600000)\n",
    "            return (name + ' ' + models[0][key]['tree_count'] + ' tree(s) (RAM x' + ram_count + ')', key, (name + ' (RAM x' + ram_count + ')', int(models[0][key]['tree_count'])))\n",
    "        elif name == 'MCNN':\n",
    "            if models[key]['cleaning'] == '1':\n",
    "                return ('MCNN Origin ' + models[0][key]['cluster_count'] + ' clusters', key, ('MCNN Origin', int(models[0][key]['cluster_count'])))\n",
    "            elif models[key]['cleaning'] == '2':\n",
    "                return ('MCNN Mixe ' + models[0][key]['cluster_count'] + ' clusters', key, ('MCNN Mixe', int(models[0][key]['cluster_count'])))\n",
    "            else:\n",
    "                return ('MCNN OrpailleCC ' + models[0][key]['cluster_count'] + ' clusters', key, ('MCNN OrpailleCC', int(models[0][key]['cluster_count'])))\n",
    "        else:\n",
    "            return (name, key, (name, 0))\n",
    "    ####### Controlling the datasets 1/4 ########\n",
    "    knn_offline_f1 = {'banos_6': 0.86, 'banos_6_v1': 0.86, 'banos_6_v2': 0.86, 'banos_6_v3': 0.86, 'banos_6_v4': 0.86, 'banos_6_v5': 0.86, 'banos_6_v6': 0.86, 'banos_6_v7': 0.86, 'recofit_6': 0.40, 'drift_6' : 0.86}\n",
    "    #(print name, key in models, tuple for sorting)\n",
    "    keys = [add_key(key) for key in models[0] if models[0][key]['fullname'] != 'Previous']\n",
    "    #grounp the third and second value to use dict to do a unique\n",
    "    keys = dict([(key[0], (key[1], key[2])) for key in keys]).items()\n",
    "    #Unpack the value part to separate the key and the sorting tuple\n",
    "    keys = [(key[0], key[1][0], key[1][1]) for key in keys]\n",
    "    keys = sorted(keys, key = lambda x: x[2])\n",
    "    names = [key[0] for key in keys]\n",
    "    print(names)\n",
    "    plt.rcParams.update({'font.size': 33})\n",
    "    ####### Controlling the datasets 2/4 ########\n",
    "    #list_datastets = ['banos_6']\n",
    "    list_datasets = ['banos_6', 'banos_6_v1', 'banos_6_v2', 'banos_6_v3','banos_6_v4', 'banos_6_v5', 'banos_6_v6','recofit_6']\n",
    "    for dataset_name in list_datasets:\n",
    "        print('Dataset: ' + dataset_name)\n",
    "        daty, daty_std = [], []\n",
    "        for i, precision in enumerate(PRECISIONS):\n",
    "            datytmp = output[i][output[i].file.str.contains(dataset_name)]\n",
    "            daty_stdtmp = datytmp[['fullname', 'element_count', 'f1', 'accuracy', 'memory']].groupby(['fullname', 'element_count']).std().reset_index()\n",
    "            datytmp = datytmp[['fullname', 'element_count', 'f1', 'accuracy', 'memory']].groupby(['fullname', 'element_count']).mean().reset_index()\n",
    "            daty.append(datytmp)\n",
    "            daty_std.append(daty_stdtmp)\n",
    "        #ACCURACY\n",
    "        for ram in ['1.0)','2.0)', '5.0)']:\n",
    "            fig = plt.figure(figsize=(23.38582, 16.53544))\n",
    "            for name in names:\n",
    "                if name[-4:]==ram:\n",
    "                    for i, precision in enumerate(PRECISIONS):\n",
    "                        style, color = line_style(name, precision)\n",
    "                        plt.plot(daty[i][daty[i].fullname == name]['element_count'], daty[i][daty[i].fullname == name]['accuracy'], markevery=0.1, markersize=15, label=\"{}, {}\".format(precision,name[8:-19]), color=color, linestyle=style)\n",
    "            plt.legend(prop={\"size\":20},bbox_to_anchor=(2, 1), ncol=8)\n",
    "            x = [a for a in daty[i][daty[i].fullname == name]['element_count']]\n",
    "            y = [knn_offline_f1[dataset_name] for a in daty[i][daty[i].fullname == name]['element_count']]\n",
    "            plt.plot(x, y, color='#000000', linestyle='-.', label='kNN Offline')\n",
    "            plt.ylim(0,1)\n",
    "            plt.ylabel(\"Accuracy\")\n",
    "            plt.xlabel(\"Element\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_directory + \"/\" + dataset_name + \"_accuracy_RAM(x{}.png\".format(ram))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "            #F1 Score DIF\n",
    "            fig = plt.figure(figsize=(23.38582, 16.53544))\n",
    "            for name in names:\n",
    "                if name[-4:]==ram:\n",
    "                    for i, precision in enumerate(PRECISIONS):\n",
    "                        style, color = line_style(name, precision)\n",
    "                        plt.plot(daty[i][daty[i].fullname == name]['element_count'],daty[i][daty[i].fullname == name]['f1']-daty[-1][daty[-1].fullname == name]['f1'], markevery=0.1, markersize=15, label=\"{}, {}\".format(precision,name[8:-19]), color=color, linestyle=style)\n",
    "            plt.ylabel(\"F1 score difference\")\n",
    "            plt.xlabel(\"Element\")\n",
    "            plt.ylim(-0.21,0.05)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_directory + \"/\" + dataset_name + \"_f1_difference_RAM(x{}.png\".format(ram))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "            #F1\n",
    "            fig = plt.figure(figsize=(23.38582, 16.53544))\n",
    "            for name in names:\n",
    "                if name[-4:]==ram:\n",
    "                    for i, precision in enumerate(PRECISIONS):\n",
    "                        style, color = line_style(name, precision)\n",
    "                        plt.plot(daty[i][daty[i].fullname == name]['element_count'], daty[i][daty[i].fullname == name]['f1'], markevery=0.1, markersize=15, label=\"{}, {}\".format(precision,name[8:-19]), color=color, linestyle=style)\n",
    "            x = [a for a in daty[i][daty[i].fullname == name]['element_count']]\n",
    "            y = [knn_offline_f1[dataset_name] for a in daty[i][daty[i].fullname == name]['element_count']]\n",
    "            plt.plot(x, y, color='#000000', linestyle='-.', label='kNN Offline')\n",
    "            #plt.legend(prop={\"size\":20},ncol=4)\n",
    "            plt.ylim(0,1)\n",
    "            plt.ylabel(\"F1\")\n",
    "            plt.xlabel(\"Element\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_directory + \"/\" + dataset_name + \"_f1_RAM(x{}.png\".format(ram))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "            #F1 dev\n",
    "            fig = plt.figure(figsize=(23.38582, 16.53544))\n",
    "            for name in names:\n",
    "                if name[-4:]==ram:\n",
    "                    for i, precision in enumerate(PRECISIONS):\n",
    "                        style, color = line_style(name, precision)\n",
    "                        y1 = daty[i][daty[i].fullname == name]['f1'] - daty_std[i][daty_std[i].fullname == name]['f1']\n",
    "                        y2 = daty[i][daty[i].fullname == name]['f1'] + daty_std[i][daty_std[i].fullname == name]['f1']\n",
    "                        plt.plot(daty[i][daty[i].fullname == name]['element_count'], daty[i][daty[i].fullname == name]['f1'], color=color, linestyle=style, label=\"{}, {}\".format(precision,name[8:-19]), markevery=0.1, markersize=15)\n",
    "                        plt.fill_between(daty_std[i][daty_std[i].fullname == name]['element_count'], y1, y2, color=color, linestyle=style, alpha=0.05)\n",
    "            x = [a for a in daty[i][daty[i].fullname == name]['element_count']]\n",
    "            y = [knn_offline_f1[dataset_name] for a in daty[i][daty[i].fullname == name]['element_count']]\n",
    "            plt.plot(x, y, color='#000000', linestyle='-.', label='kNN Offline')\n",
    "            #plt.legend(prop={\"size\":20},ncol=4)\n",
    "            plt.ylim(0,1)\n",
    "            plt.ylabel(\"F1 +- Deviation\")\n",
    "            plt.xlabel(\"Element\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_directory + \"/\" + dataset_name + \"_f1_dev_RAM(x{}.png\".format(ram))\n",
    "            plt.clf()\n",
    "            #Dev only of F1\n",
    "            fig = plt.figure(figsize=(23.38582, 16.53544))\n",
    "            for name in names:\n",
    "                if name[-4:]==ram:\n",
    "                    for i, precision in enumerate(PRECISIONS):\n",
    "                        style, color = line_style(name, precision)\n",
    "                        plt.plot(daty_std[i][daty_std[i].fullname == name]['element_count'], daty_std[i][daty_std[i].fullname == name]['f1'], color=color, linestyle=style, label=\"{}, {}\".format(precision,name[8:-19]), markevery=0.1, markersize=15)\n",
    "            #plt.legend(prop={\"size\":20},ncol=4)\n",
    "            plt.ylabel(\"F1 Deviation\")\n",
    "            plt.xlabel(\"Element\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_directory + \"/\" + dataset_name + \"_dev_RAM(x{}.png\".format(ram))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "    daty_52, daty_std_52 = [], []\n",
    "    for i, dataset in enumerate(list_datasets[:-1]):\n",
    "        datytmp = output[-1][output[-1].file.str.contains(dataset)]\n",
    "        daty_stdtmp = datytmp[['fullname', 'element_count', 'f1', 'accuracy', 'memory']].groupby(['fullname', 'element_count']).std().reset_index()\n",
    "        datytmp = datytmp[['fullname', 'element_count', 'f1', 'accuracy', 'memory']].groupby(['fullname', 'element_count']).mean().reset_index()\n",
    "        daty_52.append(datytmp)\n",
    "        daty_std_52.append(daty_stdtmp)\n",
    "    \n",
    "    for precision in [1,2,3,4,5,6,7,8]:\n",
    "        print('Precision: {}'.format(precision))\n",
    "        daty, daty_std = [], []\n",
    "        for i, dataset in enumerate(list_datasets[:-1]):\n",
    "            datytmp = output[precision-1][output[precision-1].file.str.contains(dataset)]\n",
    "            daty_stdtmp = datytmp[['fullname', 'element_count', 'f1', 'accuracy', 'memory']].groupby(['fullname', 'element_count']).std().reset_index()\n",
    "            datytmp = datytmp[['fullname', 'element_count', 'f1', 'accuracy', 'memory']].groupby(['fullname', 'element_count']).mean().reset_index()\n",
    "            daty.append(datytmp)\n",
    "            daty_std.append(daty_stdtmp)\n",
    "            plt.close()\n",
    "        #F1\n",
    "        for ram in ['1.0)','2.0)', '5.0)']:\n",
    "            fig = plt.figure(figsize=(23.38582, 16.53544))\n",
    "            for name in names:\n",
    "                if name[-4:]==ram:\n",
    "                    for i, dataset in enumerate(list_datasets[:-1]):\n",
    "                        if int(name[9:-19])==1:\n",
    "                            style='-'\n",
    "                        elif int(name[9:-19])==5:\n",
    "                            style='--'\n",
    "                        elif int(name[9:-19])==10:\n",
    "                            style='-.'\n",
    "                        elif int(name[9:-19])==50:\n",
    "                            style=':'\n",
    "                        if i>=7:\n",
    "                            color='royalblue'\n",
    "                        elif i>=6:\n",
    "                            color='green'\n",
    "                        elif i>=5:\n",
    "                            color='yellowgreen'\n",
    "                        elif i>=4:\n",
    "                            color='gold'\n",
    "                        elif i>=3:\n",
    "                            color='orange'\n",
    "                        elif i>=2:\n",
    "                            color='chocolate'\n",
    "                        elif i>=1:\n",
    "                            color='red'\n",
    "                        else:\n",
    "                            color='violet'\n",
    "                        plt.plot(daty[i][daty[i].fullname == name]['element_count'], daty[i][daty[i].fullname == name]['f1'], markevery=0.1, markersize=15, label=\"{}, {}\".format(dataset, name[8:-19]), color=color, linestyle=style)\n",
    "            x = [a for a in daty[i][daty[i].fullname == name]['element_count']]\n",
    "            y = [knn_offline_f1[dataset] for a in daty[i][daty[i].fullname == name]['element_count']]\n",
    "            plt.plot(x, y, color='#000000', linestyle='-.', label='kNN Offline')\n",
    "            plt.legend(prop={\"size\":20},ncol=4)\n",
    "            plt.ylim(0,1)\n",
    "            plt.ylabel(\"F1\")\n",
    "            plt.xlabel(\"Element\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_directory + \"/precision_{}_f1_RAM(x{}.png\".format(precision,ram))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "        #F1 Dif\n",
    "            fig = plt.figure(figsize=(23.38582, 16.53544))\n",
    "            for name in names:\n",
    "                if name[-4:]==ram:\n",
    "                    for i, dataset in enumerate(list_datasets[:-1]):\n",
    "                        if int(name[9:-19])==1:\n",
    "                            style='-'\n",
    "                        elif int(name[9:-19])==5:\n",
    "                            style='--'\n",
    "                        elif int(name[9:-19])==10:\n",
    "                            style='-.'\n",
    "                        elif int(name[9:-19])==50:\n",
    "                            style=':'\n",
    "                        if i>=7:\n",
    "                            color='royalblue'\n",
    "                        elif i>=6:\n",
    "                            color='green'\n",
    "                        elif i>=5:\n",
    "                            color='yellowgreen'\n",
    "                        elif i>=4:\n",
    "                            color='gold'\n",
    "                        elif i>=3:\n",
    "                            color='orange'\n",
    "                        elif i>=2:\n",
    "                            color='chocolate'\n",
    "                        elif i>=1:\n",
    "                            color='red'\n",
    "                        else:\n",
    "                            color='violet'\n",
    "                        plt.plot(daty[i][daty[i].fullname == name]['element_count'], daty[i][daty[i].fullname == name]['f1']-daty_52[i][daty_52[i].fullname == name]['f1'], markevery=0.1, markersize=15, label=\"{}, {}\".format(dataset, name[8:-19]), color=color, linestyle=style)\n",
    "            plt.legend(prop={\"size\":20},ncol=4)\n",
    "            plt.ylabel(\"F1 score difference\")\n",
    "            plt.xlabel(\"Element\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_directory + \"/precision_{}_f1_difference_RAM(x{}.png\".format(precision,ram))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "def print_exponents(output, output_runs, models, output_directory=\".\"):\n",
    "    ####### Controlling the datasets 1/4 ########\n",
    "    knn_offline_f1 = {'banos_6': 0.86, 'banos_6_v1': 0.86, 'banos_6_v2': 0.86, 'banos_6_v3': 0.86, 'banos_6_v4': 0.86, 'banos_6_v5': 0.86, 'banos_6_v6': 0.86, 'banos_6_v7': 0.86, 'recofit_6': 0.40, 'drift_6' : 0.86}\n",
    "    #(print name, key in models, tuple for sorting)\n",
    "    keys = [add_key(key) for key in models[0] if models[0][key]['fullname'] != 'Previous']\n",
    "    #grounp the third and second value to use dict to do a unique\n",
    "    keys = dict([(key[0], (key[1], key[2])) for key in keys]).items()\n",
    "    #Unpack the value part to separate the key and the sorting tuple\n",
    "    keys = [(key[0], key[1][0], key[1][1]) for key in keys]\n",
    "    keys = sorted(keys, key = lambda x: x[2])\n",
    "    names = [key[0] for key in keys]\n",
    "    print(names)\n",
    "    plt.rcParams.update({'font.size': 33})\n",
    "    ####### Controlling the datasets 2/4 ########\n",
    "    list_datasets = ['banos_6', 'banos_6_v1', 'banos_6_v2', 'banos_6_v3','banos_6_v4', 'banos_6_v5', 'banos_6_v6','recofit_6']\n",
    "    for dataset_name in list_datasets:\n",
    "        print('Dataset: ' + dataset_name)\n",
    "        daty, daty_std = [], []\n",
    "        for i, exponent in enumerate(EXPONENTS):\n",
    "            datytmp = output[i][output[i].file.str.contains(dataset_name)]\n",
    "            daty_stdtmp = datytmp[['fullname', 'element_count', 'f1', 'accuracy', 'memory']].groupby(['fullname', 'element_count']).std().reset_index()\n",
    "            datytmp = datytmp[['fullname', 'element_count', 'f1', 'accuracy', 'memory']].groupby(['fullname', 'element_count']).mean().reset_index()\n",
    "            daty.append(datytmp)\n",
    "            daty_std.append(daty_stdtmp)\n",
    "        for ram in ['1.0)','2.0)','5.0)']:\n",
    "            #F1 Score DIF\n",
    "            fig = plt.figure(figsize=(23.38582, 16.53544))\n",
    "            for name in names:\n",
    "                if name==ram:\n",
    "                    for i, exponent  in enumerate(EXPONENTS):\n",
    "                        style, color = line_style(name, exponent)\n",
    "                        plt.plot(daty[i][daty[i].fullname == name]['element_count'],daty[i][daty[i].fullname == name]['f1']-daty[-1][daty[-1].fullname == name]['f1'], markevery=0.1, markersize=15, label=\"{}, {}\".format(exponent,name[8:-19]), color=color, linestyle=style)\n",
    "            plt.legend(prop={\"size\":20})\n",
    "            plt.ylabel(\"F1 score difference\")\n",
    "            plt.xlabel(\"Element\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_directory + \"/\" + dataset_name + \"_f1_difference_RAM(x{}.png\".format(ram))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "            #F1\n",
    "            fig = plt.figure(figsize=(23.38582, 16.53544))\n",
    "            for name in names:\n",
    "                if name[-4:]==ram:\n",
    "                    for i, exponent in enumerate(EXPONENTS):\n",
    "                        style, color = line_style(name, exponent)\n",
    "                        plt.plot(daty[i][daty[i].fullname == name]['element_count'], daty[i][daty[i].fullname == name]['f1'], markevery=0.1, markersize=15, label=\"{}, {}\".format(exponent,name[8:-19]), color=color, linestyle=style)\n",
    "            x = [a for a in daty[i][daty[i].fullname == name]['element_count']]\n",
    "            y = [knn_offline_f1[dataset_name] for a in daty[i][daty[i].fullname == name]['element_count']]\n",
    "            plt.plot(x, y, color='#000000', linestyle='-.', label='kNN Offline')\n",
    "            plt.legend(prop={\"size\":20})\n",
    "            plt.ylim(0,1)\n",
    "            plt.ylabel(\"F1\")\n",
    "            plt.xlabel(\"Element\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_directory + \"/\" + dataset_name + \"_f1_RAM(x{}.png\".format(ram))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "            #F1 dev\n",
    "            fig = plt.figure(figsize=(23.38582, 16.53544))\n",
    "            for name in names:\n",
    "                if name[-4:]==ram:\n",
    "                    for i, exponent in enumerate(EXPONENTS):\n",
    "                        style, color = line_style(name, exponent)\n",
    "                        y1 = daty[i][daty[i].fullname == name]['f1'] - daty_std[i][daty_std[i].fullname == name]['f1']\n",
    "                        y2 = daty[i][daty[i].fullname == name]['f1'] + daty_std[i][daty_std[i].fullname == name]['f1']\n",
    "                        plt.plot(daty[i][daty[i].fullname == name]['element_count'], daty[i][daty[i].fullname == name]['f1'], color=color, linestyle=style, label=\"{}, {}\".format(exponent,name[8:-19]), markevery=0.1, markersize=15)\n",
    "                        plt.fill_between(daty_std[i][daty_std[i].fullname == name]['element_count'], y1, y2, color=color, linestyle=style, alpha=0.05)\n",
    "            x = [a for a in daty[i][daty[i].fullname == name]['element_count']]\n",
    "            y = [knn_offline_f1[dataset_name] for a in daty[i][daty[i].fullname == name]['element_count']]\n",
    "            plt.plot(x, y, color='#000000', linestyle='-.', label='kNN Offline')\n",
    "            plt.legend(prop={\"size\":20})\n",
    "            plt.ylim(0,1)\n",
    "            plt.ylabel(\"F1 +- Deviation\")\n",
    "            plt.xlabel(\"Element\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_directory + \"/\" + dataset_name + \"_f1_dev_RAM(x{}.png\".format(ram))\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result plots for mantissa precision comparison and ordering comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main tool used for data analysis.\n",
    "ins = 'node'\n",
    "dir_name = '{}_results'.format(ins)\n",
    "exp = '11'\n",
    "out_name = '{}_{}_plots'.format(exp, ins)\n",
    "output_lst, output_run_lst, models_lst = [], [], []\n",
    "PRECISIONS = [i for i in range(1,52)]\n",
    "for i in PRECISIONS:\n",
    "    output, output_runs, models = process_output(\"{}/{}_output_{}\".format(dir_name,exp,i),\"{}/{}_output_runs_{}\".format(dir_name,exp,i),\"{}/{}_models_{}.csv\".format(dir_name,exp,i))\n",
    "    output_lst.append(output)\n",
    "    output_run_lst.append(output_runs)\n",
    "    models_lst.append(models)\n",
    "print_results(output_lst, output_run_lst, models_lst, output_directory=out_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result plots for exponent precision comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the exponents all on one graph\n",
    "dir_name = 'exp_whole_results'\n",
    "precision = '52'\n",
    "out_name = 'exp_whole_plots'\n",
    "output_lst, output_run_lst, models_lst = [], [], []\n",
    "EXPONENTS = range(3,12)\n",
    "for e in EXPONENTS:\n",
    "    output, output_runs, models = process_output(\"{}/{}_output_{}\".format(dir_name,e,precision),\"{}/{}_output_runs_{}\".format(dir_name,e,precision),\"{}/{}_models_{}.csv\".format(dir_name,e,precision))\n",
    "    output_lst.append(output)\n",
    "    output_run_lst.append(output_runs)\n",
    "    models_lst.append(models)\n",
    "print_exponents(output_lst, output_run_lst, models_lst, output_directory=out_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
